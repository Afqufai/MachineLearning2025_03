{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a6a61b",
   "metadata": {},
   "source": [
    "# Praktikum 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b7d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ee360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "from annoy import AnnoyIndex\n",
    "import hnswlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('/content/drive/MyDrive/Dataset/songs_with_attributes_and_lyrics.csv')\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features].values\n",
    "print(f\"Dataset loaded with {X.shape[0]} samples and {X.shape[1]} features.\")\n",
    "\n",
    "\n",
    "# Standarisasi fitur\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Features scaled.\")\n",
    "\n",
    "k = 10  # jumlah nearest neighbors\n",
    "\n",
    "# -------------------------------\n",
    "# Exact Nearest Neighbor (brute-force) on a smaller subset for feasibility\n",
    "# -------------------------------\n",
    "print(\"\\nRunning Exact NN (Brute Force) on a subset...\")\n",
    "n_exact_samples = 1000 # Use a smaller subset for brute force\n",
    "X_exact_subset = X_scaled[:n_exact_samples]\n",
    "\n",
    "start = time.time()\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "nn.fit(X_exact_subset)\n",
    "dist_exact_subset, idx_exact_subset = nn.kneighbors(X_exact_subset)\n",
    "time_exact_subset = time.time() - start\n",
    "print(f\"Exact NN on subset done in {time_exact_subset:.3f} s\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Annoy on the full dataset\n",
    "# -------------------------------\n",
    "print(\"\\nRunning Annoy on the full dataset...\")\n",
    "start = time.time()\n",
    "f = X_scaled.shape[1]\n",
    "index_annoy = AnnoyIndex(f, 'euclidean')\n",
    "for i, v in enumerate(X_scaled):\n",
    "    index_annoy.add_item(i, v)\n",
    "index_annoy.build(10)\n",
    "# Query Annoy with the subset used for Exact NN to compare\n",
    "idx_annoy_subset = [index_annoy.get_nns_by_vector(X_scaled[i], k) for i in range(n_exact_samples)]\n",
    "time_annoy = time.time() - start\n",
    "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# HNSW on the full dataset\n",
    "# -------------------------------\n",
    "print(\"\\nRunning HNSW on the full dataset...\")\n",
    "start = time.time()\n",
    "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
    "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=200, M=16)\n",
    "p_hnsw.add_items(X_scaled)\n",
    "p_hnsw.set_ef(200)\n",
    "# Query HNSW with the subset used for Exact NN to compare\n",
    "idx_hnsw_subset, dist_hnsw_subset = p_hnsw.knn_query(X_scaled[:n_exact_samples], k=k)\n",
    "time_hnsw = time.time() - start\n",
    "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# FAISS IVF on the full dataset\n",
    "# -------------------------------\n",
    "print(\"\\nRunning FAISS IVF on the full dataset...\")\n",
    "start = time.time()\n",
    "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
    "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], nlist=100, metric=faiss.METRIC_L2)\n",
    "index_faiss.train(X_scaled)\n",
    "index_faiss.add(X_scaled)\n",
    "index_faiss.nprobe = 10\n",
    "# Query FAISS with the subset used for Exact NN to compare\n",
    "dist_faiss_subset, idx_faiss_subset = index_faiss.search(X_scaled[:n_exact_samples], k)\n",
    "time_faiss = time.time() - start\n",
    "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# Contoh tampilkan top-5 neighbors dari item pertama (dari subset)\n",
    "# -------------------------------\n",
    "print(\"\\nTop-5 neighbors for first song (from subset):\")\n",
    "# Ensure indices are within the subset size for Exact NN\n",
    "print(f\"Exact NN: {idx_exact_subset[0][:5]}\")\n",
    "print(f\"Annoy:    {idx_annoy_subset[0][:5]}\")\n",
    "print(f\"HNSW:     {idx_hnsw_subset[0][:5]}\")\n",
    "print(f\"FAISS:    {idx_faiss_subset[0][:5]}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Tampilkan ringkasan waktu\n",
    "# Note: Exact NN time is for the subset, others are for the full dataset (build + subset query)\n",
    "# -------------------------------\n",
    "print(\"\\n=== Ringkasan Waktu (detik) ===\")\n",
    "print(f\"Exact NN (Subset): {time_exact_subset:.3f}\")\n",
    "print(f\"Annoy (Full):      {time_annoy:.3f}\")\n",
    "print(f\"HNSW (Full):       {time_hnsw:.3f}\")\n",
    "print(f\"FAISS (Full):      {time_faiss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06dafc8",
   "metadata": {},
   "source": [
    "Karena besarnya dataset, beberapa operasi seperti bruteforce akan memakan waktu yang lama untuk dijalankan pada cloud."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
